GenAI Day 7 â€“ Hugging Face AI Text Assistant
ğŸ“Œ Project Overview

This project is a local AI Text Assistant built using Hugging Face Transformers.

It supports:

ğŸ“ Text Summarization

â“ Question Answering (Context-based)

âœï¸ Creative Content Generation

All models run locally on CPU or GPU.

ğŸ›  Technologies Used

Python

PyTorch

Hugging Face Transformers

Streamlit (for UI)

CUDA (optional for GPU acceleration)

ğŸ¤– Models Used
Task	Model
Summarization	facebook/bart-large-cnn
Question Answering	google/flan-t5-base
Text Generation	gpt2
ğŸ“‚ Project Structure
day6_genai/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
âš™ï¸ Installation
1ï¸âƒ£ Create virtual environment
python -m venv mygenaivenv
mygenaivenv\Scripts\activate
2ï¸âƒ£ Install dependencies
pip install -r requirements.txt
â–¶ï¸ Run the App
streamlit run app.py
ğŸ§  How It Works

Models are loaded once using Hugging Face pipeline.

GPU is automatically detected.

Each function calls its respective model.

Results are returned and displayed via Streamlit UI.

ğŸš€ Future Improvements

Add RAG with FAISS

Add model selection dropdown

Add conversation memory

Add quantized models for low RAM systems

ğŸ† What You Learned in Day 7

Using Hugging Face pipelines

Running LLM locally

Device management (CPU vs GPU)

Controlling generation parameters

Building modular AI utilities