# Day 4 â€“ Lightweight Fine-Tuning with LoRA (PEFT)

This project demonstrates **lightweight fine-tuning of a Large Language Model using LoRA (Low-Rank Adaptation)** on a very small custom dataset. The goal is to understand **fine-tuning vs prompting**, overfitting risks, and how **PEFT (Parameter-Efficient Fine-Tuning)** works in practice.

---

## ğŸš€ What This Project Covers

* What fine-tuning is and **when NOT to do it**
* Difference between **prompting vs fine-tuning**
* Overfitting risks with small datasets
* **LoRA (Low-Rank Adaptation)** â€“ a PEFT technique
* Fine-tuning a model with **20â€“50 samples**
* Running inference using a fine-tuned adapter

---

## ğŸ§  Technique Used

**LoRA (Low-Rank Adaptation)**

* Category: **PEFT (Parameter-Efficient Fine-Tuning)**
* Base model weights are frozen
* Only small adapter layers are trained
* Very low compute and memory cost
* Industry-standard approach for LLM customization

---

## ğŸ—ï¸ Model & Tools

* **Base Model:** `google/flan-t5-small`
* **Framework:** Hugging Face Transformers
* **PEFT Library:** `peft`
* **Language:** Python

---

## ğŸ“‚ Project Structure

```
day4_genai/
â”‚â”€â”€ data.json                # Small custom training dataset
â”‚â”€â”€ train.py                 # LoRA fine-tuning script
â”‚â”€â”€ test.py                  # Inference / testing script
â”‚â”€â”€ finetuned_model/
â”‚   â””â”€â”€ checkpoint-45/       # Saved LoRA adapter
â”‚       â”œâ”€â”€ adapter_config.json
â”‚       â””â”€â”€ adapter_model.safetensors
```

---

## ğŸ“Š Dataset Example

```json
{
  "input": "Hello",
  "output": "Hi! How can I help you today?"
}
```

> âš ï¸ Note: The dataset is intentionally small to demonstrate **overfitting and behavior changes** during fine-tuning.

---

## ğŸƒ How to Run

### 1ï¸âƒ£ Create Virtual Environment

```bash
python -m venv mygenaivenv
mygenaivenv\Scripts\activate
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install transformers datasets peft accelerate torch
```

### 3ï¸âƒ£ Train (LoRA Fine-Tuning)

```bash
python train.py
```

### 4ï¸âƒ£ Test the Fine-Tuned Model

```bash
python test.py
```

---

## ğŸ§ª Observations

* With very small datasets, the model may:

  * Repeat tokens
  * Give short or conservative outputs
* This behavior demonstrates **overfitting**, which is expected
* Despite this, LoRA successfully influences model behavior

---

## ğŸ“Œ Key Learnings

* Fine-tuning is **expensive** compared to prompting
* LoRA enables cheap, fast customization
* Small datasets = high overfitting risk
* Always match the **same base model** during training and inference

---

## ğŸ“š When to Use Fine-Tuning

âœ… Domain-specific language
âœ… Consistent response style
âœ… Repeated task patterns

âŒ Simple Q&A
âŒ One-off tasks
âŒ Small improvements achievable via prompting

---

## ğŸ”® Next Improvements

* Add more diverse training samples
* Compare **base model vs LoRA outputs**
* Try Prompt Tuning / Prefix Tuning
* Increase LoRA rank (`r` value)
* Log training loss and evaluation metrics

---

## ğŸ Conclusion

This project provides a **hands-on, minimal example** of lightweight fine-tuning using LoRA. It is ideal for learning PEFT concepts and understanding the trade-offs between prompting and fine-tuning.

---

ğŸ‘©â€ğŸ’» *Built as part of a GenAI learning journey*
